# AI Provider Configuration
# Choose one of: openai, anthropic, gemini, ollama
AI_PROVIDER=openai

# AI Model (optional - uses provider defaults if not specified)
# OpenAI: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# Gemini: gemini-pro, gemini-1.5-pro, gemini-1.5-flash
# Ollama: llama2, codellama, mistral, mixtral, etc.
AI_MODEL=gpt-4

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic Configuration (Claude)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Google Gemini Configuration
GEMINI_API_KEY=your-gemini-api-key-here
# Alternative variable name
# GOOGLE_API_KEY=your-google-api-key-here

# Ollama Configuration (local LLMs)
# Only required if using custom Ollama instance
# AI_BASE_URL=http://localhost:11434

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379

# Vault Configuration
VAULT_ADDR=http://vault:8200
VAULT_TOKEN=myroot

# Ansible Configuration
ANSIBLE_HOST_KEY_CHECKING=False

# Logging
LOG_LEVEL=info

# Node Environment
NODE_ENV=production
